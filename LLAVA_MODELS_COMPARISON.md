# Comparaison des ModÃ¨les Vision pour Poietic Generator

**Date**: 2025-01-23  
**Question**: Peut-on passer Ã  LLaVA 13B ou autre chose ?

---

## ðŸ“Š **ModÃ¨les Disponibles sur Ollama**

### **LLaVA (Large Language and Vision Assistant)**

| ModÃ¨le | Taille | Params | VRAM | Vitesse | QualitÃ© Instructions | Disponible Ollama |
|--------|--------|--------|------|---------|---------------------|-------------------|
| **llava:7b** (actuel) | 4.7 GB | 7B | 8 GB | âš¡âš¡âš¡ Rapide (100-150s) | â­â­ Moyen | âœ… `ollama run llava:7b` |
| **llava:13b** | 8 GB | 13B | 16 GB | âš¡âš¡ Moyen (200-300s) | â­â­â­ Bon | âœ… `ollama run llava:13b` |
| **llava:34b** | 20 GB | 34B | 32 GB | âš¡ Lent (400-600s) | â­â­â­â­ Excellent | âœ… `ollama run llava:34b` |

---

## ðŸ†š **Alternatives Vision**

### **1. Llama 3.2 Vision (Meta)**
```bash
ollama run llama3.2-vision:11b
ollama run llama3.2-vision:90b
```

| Version | Taille | Params | VRAM | Vitesse | QualitÃ© | Notes |
|---------|--------|--------|------|---------|---------|-------|
| **11b** | 7.9 GB | 11B | 16 GB | âš¡âš¡ Moyen | â­â­â­ Bon | Meilleur que LLaVA 7B |
| **90b** | 55 GB | 90B | 64 GB | ðŸŒ TrÃ¨s lent | â­â­â­â­â­ Excellent | GPU puissant requis |

**Avantages** :
- âœ… Meilleure comprÃ©hension des instructions
- âœ… Moins d'erreurs de format
- âœ… Vision plus prÃ©cise

**InconvÃ©nients** :
- âŒ VRAM importante requise
- âŒ Plus lent que LLaVA 7B

---

### **2. MiniCPM-V (OpenBMB)**
```bash
ollama run minicpm-v:8b
```

| Version | Taille | Params | VRAM | Vitesse | QualitÃ© | Notes |
|---------|--------|--------|------|---------|---------|-------|
| **8b** | 5.4 GB | 8B | 10 GB | âš¡âš¡âš¡ Rapide | â­â­â­ Bon | Compact et efficace |

**Avantages** :
- âœ… TrÃ¨s compact (5.4 GB)
- âœ… Rapide
- âœ… Bonne vision

**InconvÃ©nients** :
- âš ï¸ Moins testÃ© que LLaVA
- âš ï¸ Documentation limitÃ©e

---

### **3. Moondream (vikhyatk)**
```bash
ollama run moondream:latest
```

| Version | Taille | Params | VRAM | Vitesse | QualitÃ© | Notes |
|---------|--------|--------|------|---------|---------|-------|
| **1.8b** | 1.7 GB | 1.8B | 4 GB | âš¡âš¡âš¡âš¡ TrÃ¨s rapide | â­â­ Basique | Ultra lÃ©ger |

**Avantages** :
- âœ… ExtrÃªmement lÃ©ger (1.7 GB)
- âœ… TrÃ¨s rapide (30-60s)
- âœ… Faible VRAM

**InconvÃ©nients** :
- âŒ QualitÃ© mÃ©diocre pour tÃ¢ches complexes
- âŒ Pas adaptÃ© pour notre usage

---

## ðŸŽ¯ **Recommandations**

### **Option 1 : LLaVA 13B (Upgrade conservatif)** â­ RECOMMANDÃ‰

**Commande** :
```bash
# Sur le serveur OVH avec Ollama
ollama pull llava:13b
```

**Modification** :
```javascript
// Dans public/js/llm-adapters/llava-v2.js (ligne ~140)
const payload = {
    model: "llava:13b",  // Au lieu de "llava:7b"
    // ...
};
```

**Avantages** :
- âœ… **Meilleure qualitÃ©** : Moins d'erreurs de coordonnÃ©es, meilleur respect du format
- âœ… **Compatible** : MÃªme API que LLaVA 7B
- âœ… **Raisonnable** : VRAM 16 GB (probablement OK sur OVH)
- âœ… **Vitesse acceptable** : 200-300s (avec timeout 300s, Ã§a passe)

**InconvÃ©nients** :
- âš ï¸ Plus lent : 200-300s au lieu de 100-150s
- âš ï¸ Plus de VRAM : 16 GB au lieu de 8 GB

---

### **Option 2 : Llama 3.2 Vision 11B (Alternative moderne)**

**Commande** :
```bash
ollama pull llama3.2-vision:11b
```

**Modification** :
```javascript
const payload = {
    model: "llama3.2-vision:11b",
    // ...
};
```

**Avantages** :
- âœ… **Plus rÃ©cent** : Sorti en 2024, architecture moderne
- âœ… **Meilleure comprÃ©hension** : Moins de "hallucinations"
- âœ… **Format multimodal natif** : ConÃ§u pour vision+texte

**InconvÃ©nients** :
- âš ï¸ **Adapter l'API** : Format de requÃªte diffÃ©rent
- âš ï¸ **Moins testÃ©** : Sur notre use case spÃ©cifique

---

### **Option 3 : Garder LLaVA 7B + AmÃ©liorer les Prompts** (Safe)

**Avantages** :
- âœ… **Aucun changement serveur**
- âœ… **Pas de risque**
- âœ… **Rapide**

**InconvÃ©nients** :
- âŒ QualitÃ© limitÃ©e par le modÃ¨le 7B

---

## ðŸ” **VÃ©rification GPU OVH**

Avant de changer de modÃ¨le, vÃ©rifiez la VRAM disponible :

```bash
# Sur le serveur OVH
nvidia-smi
```

**Output attendu** :
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.10    Driver Version: 535.86.10    CUDA Version: 12.2   |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |
| N/A   45C    P8    10W /  70W |   8192MiB / 15360MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
```

**InterprÃ©tation** :
- **Tesla T4** : 15 GB VRAM â†’ **LLaVA 13B OK** âœ…
- **Tesla V100** : 32 GB VRAM â†’ **LLaVA 34B OK** âœ…
- **RTX 4090** : 24 GB VRAM â†’ **Llama 3.2 Vision 11B OK** âœ…

---

## ðŸ“Š **Tableau de DÃ©cision**

| CritÃ¨re | LLaVA 7B (actuel) | LLaVA 13B | Llama 3.2 Vision 11B |
|---------|-------------------|-----------|----------------------|
| **QualitÃ© instructions** | â­â­ | â­â­â­ | â­â­â­â­ |
| **Vitesse** | âš¡âš¡âš¡ (100-150s) | âš¡âš¡ (200-300s) | âš¡âš¡ (200-300s) |
| **VRAM requise** | 8 GB | 16 GB | 16 GB |
| **FacilitÃ© migration** | N/A | âœ… TrÃ¨s facile | âš ï¸ Adapter API |
| **Risque** | N/A | âš ï¸ Faible | âš ï¸ Moyen |
| **RecommandÃ© ?** | - | âœ… OUI | âš ï¸ Si GPU puissant |

---

## âœ… **Plan d'Action pour LLaVA 13B**

### **1. VÃ©rifier VRAM disponible**
```bash
ssh votre_serveur_ovh
nvidia-smi
```

### **2. TÃ©lÃ©charger LLaVA 13B**
```bash
ollama pull llava:13b
# Taille: ~8 GB, prend 5-10 minutes
```

### **3. Modifier le code**
```javascript
// public/js/llm-adapters/llava-v2.js (ligne ~140)
const payload = {
    model: "llava:13b",  // Changer ici
    prompt: systemMessage,
    // ... reste inchangÃ©
};
```

### **4. Tester**
1. Recharger `ai-player-v2.html` (Ctrl+Shift+R)
2. Lancer un agent
3. Observer :
   - **Moins d'erreurs de coordonnÃ©es** âœ…
   - **Meilleur respect du format** âœ…
   - **Temps de rÃ©ponse : 200-300s** (au lieu de 100-150s)

### **5. Ajuster le timeout (optionnel)**
Si les timeouts persistent :
```javascript
// public/js/llm-adapters/llava-v2.js (ligne ~152)
const controller = new AbortController();
const timeoutId = setTimeout(() => controller.abort(), 240000); // 240s (4 min)
```

---

## ðŸŽ¯ **Ma Recommandation Finale**

**Passez Ã  LLaVA 13B** si :
- âœ… VRAM â‰¥ 16 GB sur le serveur OVH
- âœ… Vous voulez **moins d'erreurs** de format/coordonnÃ©es
- âœ… Vous acceptez **+50-100s** de temps de rÃ©ponse

**Gardez LLaVA 7B** si :
- âœ… VRAM < 16 GB
- âœ… Vitesse > QualitÃ©
- âœ… Les erreurs sont acceptables

**Testez Llama 3.2 Vision 11B** si :
- âœ… VRAM â‰¥ 16 GB
- âœ… Vous voulez la **meilleure qualitÃ©**
- âœ… Vous Ãªtes prÃªt Ã  adapter l'API

---

**Voulez-vous que je vous aide Ã  migrer vers LLaVA 13B ?** ðŸš€
